

# ğŸ•µï¸â€â™‚ï¸ Sistema HÃ­brido de DetecÃ§Ã£o de Deepfakes
### *UNDB 4.0 - Projeto de VisÃ£o Computacional*

**ğŸš€ DetecÃ§Ã£o de deepfakes de nova geraÃ§Ã£o combinando anÃ¡lise determinÃ­stica e inteligÃªncia artificial**

[![Python 3.8+](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.13+-orange.svg)](https://tensorflow.org/)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.8+-green.svg)](https://opencv.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-Web_App-red.svg)](https://streamlit.io/)

---

### âš¡ **InÃ­cio RÃ¡pido**

```bash
# Instalar dependÃªncias
pip install -r requirements.txt

# Executar interface web
streamlit run app.py
```

### ğŸ¯ **O que Este Sistema Faz**

Este projeto implementa um **sistema de detecÃ§Ã£o de deepfakes com dupla abordagem** que combina:
- ğŸ” **AnÃ¡lise DeterminÃ­stica**: DetecÃ§Ã£o baseada em regras de artefatos visuais
- ğŸ§  **ClassificaÃ§Ã£o por IA**: Rede Neural Convolucional treinada para reconhecimento de padrÃµes

ConstruÃ­do com princÃ­pios de **Clean Code** e **SOLID** para arquitetura mantÃ­vel e escalÃ¡vel.

</div>

---

## ğŸ”¬ **Tecnologias Principais**

<table>
<tr>
<td width="33%">

### ğŸ **Ecossistema Python**
- **Python 3.8+** - Linguagem principal
- **Streamlit** - Interface web interativa
- **NumPy** - OperaÃ§Ãµes matemÃ¡ticas
- **Pandas** - ManipulaÃ§Ã£o de dados

</td>
<td width="33%">

### ğŸ‘ï¸ **VisÃ£o Computacional**
- **OpenCV** - Processamento de vÃ­deo e detecÃ§Ã£o facial
- **Haar Cascade** - DetecÃ§Ã£o de objetos em tempo real
- **Filtro Laplaciano** - DetecÃ§Ã£o de bordas
- **FFT** - AnÃ¡lise espectral

</td>
<td width="33%">

### ğŸ¤– **Machine Learning**
- **TensorFlow/Keras** - Framework de deep learning
- **MobileNetV2** - Base para transfer learning
- **Scikit-learn** - UtilitÃ¡rios de ML
- **Matplotlib** - VisualizaÃ§Ã£o de dados

</td>
</tr>
</table>

---

## ğŸ›ï¸ **Arquitetura do Sistema**

```mermaid
graph TB
    UI[ğŸ–¥ï¸ Interface Streamlit<br/>Upload de Arquivos & Resultados] --> VP[ğŸ“¹ Processamento de VÃ­deo]
    
    VP --> VL[ğŸ“¼ VideoLoader<br/>ExtraÃ§Ã£o de Frames]
    VP --> FE[ğŸ‘¤ FaceExtractor<br/>DetecÃ§Ã£o de ROI]
    
    VL --> DD[ğŸ” Detector DeterminÃ­stico]
    FE --> AI[ğŸ§  Classificador IA]
    
    DD --> |AnÃ¡lise de Bordas| FFT[ğŸ“Š AnÃ¡lise FFT]
    DD --> |DetecÃ§Ã£o de Blur| LAP[âš¡ Filtro Laplaciano]
    
    AI --> |Transfer Learning| MOB[ğŸ“± MobileNetV2]
    AI --> |Camadas Customizadas| CNN[ğŸŒ Classificador CNN]
    
    FFT --> HD[âš–ï¸ DecisÃ£o HÃ­brida]
    LAP --> HD
    MOB --> HD
    CNN --> HD
    
    HD --> RES[ğŸ“ˆ Resultados Finais]
```

---

## ğŸ§  **Como Funciona**

### 1ï¸âƒ£ **Processamento da Entrada de VÃ­deo**
| Etapa | Processo | Tecnologia |
|-------|----------|------------|
| ğŸ“¤ | Upload de vÃ­deo via interface Streamlit | `streamlit.file_uploader` |
| ğŸï¸ | ExtraÃ§Ã£o de metadados (FPS, resoluÃ§Ã£o, duraÃ§Ã£o) | `cv2.VideoCapture` |
| ğŸ“Š | Armazenamento temporÃ¡rio e validaÃ§Ã£o | ManipulaÃ§Ã£o de arquivos Python |

### 2ï¸âƒ£ **Pipeline de DetecÃ§Ã£o Facial**

<details>
<summary><b>ğŸ” Componente VideoLoader</b></summary>

```python
# Processamento frame por frame com padrÃ£o generator
def load_video(video_path, frame_skip=1):
    cap = cv2.VideoCapture(video_path)
    frame_number = 0
    
    while True:
        ret, frame = cap.read()
        if not ret: break
        
        if frame_number % frame_skip == 0:
            yield frame, frame_number
        frame_number += 1
```

**CaracterÃ­sticas:**
- Processamento de frames com eficiÃªncia de memÃ³ria
- Pulo de frames configurÃ¡vel
- MÃ©todos estÃ¡ticos (princÃ­pio Clean Code)

</details>

<details>
<summary><b>ğŸ‘¤ Componente FaceExtractor</b></summary>

```python
# DetecÃ§Ã£o facial com Haar Cascade com validaÃ§Ã£o de qualidade
faces = face_cascade.detectMultiScale(
    gray_frame,
    scaleFactor=1.15,
    minNeighbors=4,
    minSize=(50, 50)
)

# ValidaÃ§Ã£o de qualidade e extraÃ§Ã£o de ROI
for (x, y, w, h) in faces:
    if w >= 50 and h >= 50 and 0.8 <= w/h <= 1.2:
        face_roi = frame[y:y+h, x:x+w]
        face_resized = cv2.resize(face_roi, (224, 224))
        yield face_resized
```

**OtimizaÃ§Ãµes:**
- EqualizaÃ§Ã£o de histograma para melhor contraste
- Redimensionamento de frames para performance (mÃ¡x 1280px)
- ValidaÃ§Ã£o de proporÃ§Ã£o aspectual
- Filtragem de tamanho mÃ­nimo da face

</details>

### 3ï¸âƒ£ **Motor de DetecÃ§Ã£o Dupla**

#### ğŸ” **Detector DeterminÃ­stico**

| Tipo de AnÃ¡lise | MÃ©todo | Limiar | IndicaÃ§Ã£o |
|------------------|--------|--------|-----------|
| **AnÃ¡lise de Bordas** | VariÃ¢ncia Laplaciana | `< 100` | Blur excessivo (deepfakes antigos) |
| **AnÃ¡lise de Bordas** | VariÃ¢ncia Laplaciana | `> alto` | Aumento artificial de nitidez |
| **AnÃ¡lise Espectral** | Magnitude FFT | Picos anÃ´malos | Artefatos de frequÃªncia |
| **AnÃ¡lise Espectral** | MÃ©dia FFT | `< 10` ou `> 50` | PadrÃµes nÃ£o naturais |

#### ğŸ§  **Arquitetura do Classificador IA**

```
Entrada (224Ã—224Ã—3 RGB)
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Base MobileNetV2  â”‚ â† PrÃ©-treinado na ImageNet (congelado)
â”‚   (Extrator de      â”‚
â”‚    CaracterÃ­sticas) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GlobalAveragePool2D â”‚ â† ReduÃ§Ã£o dimensional
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dense(128, ReLU)  â”‚ â† Camada de caracterÃ­sticas customizada
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Dropout(0.5)     â”‚ â† RegularizaÃ§Ã£o
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dense(1, Sigmoid)  â”‚ â† ClassificaÃ§Ã£o binÃ¡ria
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    Probabilidade (0-1)
```

### 4ï¸âƒ£ **Tomada de DecisÃ£o HÃ­brida**

```python
# CombinaÃ§Ã£o ponderada dos mÃ©todos de detecÃ§Ã£o
score_final = (probabilidade_ia Ã— peso_ia) + (confianÃ§a_deterministico Ã— peso_det)

onde:
â”œâ”€â”€ peso_ia: ConfigurÃ¡vel pelo usuÃ¡rio (0.0 - 1.0)
â”œâ”€â”€ peso_det: 1.0 - peso_ia
â”œâ”€â”€ probabilidade_ia: SaÃ­da da CNN (0.0 = real, 1.0 = fake)
â””â”€â”€ confianÃ§a_deterministico: Score de confianÃ§a baseado em regras
```

**BenefÃ­cios:**
- âœ… Resultados interpretÃ¡veis da anÃ¡lise determinÃ­stica
- âœ… Alta precisÃ£o da classificaÃ§Ã£o por IA
- âœ… Ajuste de pesos em tempo real
- âœ… Robusto contra vÃ¡rios tipos de deepfakes

---

## ğŸš€ **Guia de InstalaÃ§Ã£o**

### **Requisitos do Sistema**

<table>
<tr>
<td>

**Requisitos MÃ­nimos**
- Python 3.8+
- 4GB RAM
- 2GB espaÃ§o livre em disco
- CPU com suporte SSE4.2

</td>
<td>

**ConfiguraÃ§Ã£o Recomendada**
- Python 3.11 ou 3.12
- 8GB RAM
- GPU com suporte CUDA
- 5GB espaÃ§o livre em disco

</td>
</tr>
</table>

### **InstalaÃ§Ã£o Passo a Passo**

<details>
<summary><b>ğŸ OpÃ§Ã£o 1: InstalaÃ§Ã£o Python PadrÃ£o</b></summary>

```bash
# 1. Clonar/Baixar o projeto
cd /caminho/para/projeto

# 2. Instalar dependÃªncias
pip install -r requirements.txt

# 3. Verificar instalaÃ§Ã£o
python -c "import cv2, tensorflow, numpy; print('âœ… Todas as dependÃªncias instaladas!')"

# 4. Criar diretÃ³rios necessÃ¡rios
mkdir -p data/input/{fake,real} data/processed data/output models
```

</details>

<details>
<summary><b>ğŸ³ OpÃ§Ã£o 2: Ambiente Virtual (Recomendado)</b></summary>

```bash
# 1. Criar ambiente virtual
python -m venv deepfake_env

# 2. Ativar ambiente
# No macOS/Linux:
source deepfake_env/bin/activate
# No Windows:
# deepfake_env\Scripts\activate

# 3. Instalar dependÃªncias
pip install -r requirements.txt

# 4. Verificar instalaÃ§Ã£o
python -c "import cv2, tensorflow, numpy; print('âœ… Ambiente pronto!')"
```

</details>

<details>
<summary><b>ğŸ”§ Solucionando Problemas de InstalaÃ§Ã£o</b></summary>

| Erro | SoluÃ§Ã£o |
|------|---------|
| `ModuleNotFoundError: cv2` | `pip install opencv-python` |
| `TensorFlow nÃ£o disponÃ­vel` | Use Python 3.11/3.12, veja `GUIA_INSTALACAO.md` |
| `PermissÃ£o negada` | Use `pip install --user` ou ambiente virtual |
| `GPU nÃ£o detectada` | Instale `tensorflow-gpu` (se CUDA disponÃ­vel) |

</details>

---

## ğŸ® **InstruÃ§Ãµes de Uso**

### **ğŸŒ Interface Web (Streamlit)**

#### **Executar a AplicaÃ§Ã£o**

```bash
# Iniciar interface web
streamlit run app.py

# Comandos alternativos
python -m streamlit run app.py    # Python genÃ©rico
py -m streamlit run app.py        # Windows
```

ğŸŒ **Acessar:** `http://localhost:8501` (abre automaticamente)

#### **Usando a Interface**

<table>
<tr>
<td width="50%">

**ğŸ“¤ Upload de VÃ­deo**
1. Clique em "Browse files" ou arraste e solte
2. Formatos suportados: MP4, AVI, MOV
3. Tamanho mÃ¡ximo: 200MB (configurÃ¡vel)

**âš™ï¸ Configurar ConfiguraÃ§Ãµes**
- FrequÃªncia de processamento de frames (1-10)
- Peso IA vs DeterminÃ­stico (0.0-1.0)
- OpÃ§Ãµes de visualizaÃ§Ã£o

</td>
<td width="50%">

**ğŸš€ Executar AnÃ¡lise**
1. Clique em "ğŸš€ Iniciar AnÃ¡lise"
2. Monitore a barra de progresso
3. Aguarde conclusÃ£o do processamento

**ğŸ“Š Ver Resultados**
- Probabilidade de autenticidade
- GrÃ¡ficos de variaÃ§Ã£o temporal
- Detalhes de artefatos visuais
- EstatÃ­sticas de processamento

</td>
</tr>
</table>

### **ğŸ¤– Treinamento do Modelo**

#### **Preparar Dados de Treinamento**

```bash
# Estrutura de diretÃ³rios
data/input/
â”œâ”€â”€ fake/           # Colocar vÃ­deos deepfake aqui
â”‚   â”œâ”€â”€ video1.mp4
â”‚   â”œâ”€â”€ video2.avi
â”‚   â””â”€â”€ ...
â””â”€â”€ real/           # Colocar vÃ­deos autÃªnticos aqui
    â”œâ”€â”€ video1.mp4
    â”œâ”€â”€ video2.mov
    â””â”€â”€ ...
```

#### **Executar Treinamento**

```bash
# Iniciar processo de treinamento
python train_model.py

# Monitorar progresso do treinamento
# - ExtraÃ§Ã£o de faces de todos os vÃ­deos
# - PreparaÃ§Ã£o do dataset (80% treino, 20% validaÃ§Ã£o)
# - Treinamento do modelo (20 Ã©pocas)
# - Salvar modelo em models/deepfake_classifier.h5
```

#### **ConfiguraÃ§Ã£o de Treinamento**

```python
# Editar train_model.py para personalizar:
EPOCHS = 20              # Ã‰pocas de treinamento
BATCH_SIZE = 16          # Tamanho do batch
FRAMES_PER_VIDEO = 10    # Faces extraÃ­das por vÃ­deo
LEARNING_RATE = 0.001    # Taxa de aprendizagem do otimizador
```

---

## ğŸ“ **Estrutura do Projeto**

<details>
<summary><b>ğŸ—‚ï¸ Ãrvore Completa de DiretÃ³rios</b></summary>

```
visÃ£o_computacional/
â”œâ”€â”€ ğŸ“„ app.py                    # Interface web Streamlit
â”œâ”€â”€ ğŸ“„ main.py                   # Pontos de entrada principais
â”œâ”€â”€ ğŸ“„ train_model.py            # Script de treinamento do modelo
â”œâ”€â”€ ğŸ“„ requirements.txt          # DependÃªncias Python
â”œâ”€â”€ ğŸ“„ video_labels.json         # Labels de vÃ­deo opcionais
â”œâ”€â”€ ğŸ“„ README.md                 # Esta documentaÃ§Ã£o
â”œâ”€â”€ ğŸ“„ GUIA_INSTALACAO.md        # Guia de instalaÃ§Ã£o
â”‚
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ ğŸ“‚ input/
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ fake/            # Treinamento: vÃ­deos deepfake
â”‚   â”‚   â””â”€â”€ ğŸ“‚ real/            # Treinamento: vÃ­deos autÃªnticos
â”‚   â”œâ”€â”€ ğŸ“‚ processed/           # Faces extraÃ­das (cache)
â”‚   â””â”€â”€ ğŸ“‚ output/              # RelatÃ³rios de anÃ¡lise e logs
â”‚
â”œâ”€â”€ ğŸ“‚ models/                   # Pesos da rede neural treinada
â”‚   â””â”€â”€ ğŸ“„ deepfake_classifier.h5
â”‚
â””â”€â”€ ğŸ“‚ src/
    â”œâ”€â”€ ğŸ“„ __init__.py
    â”‚
    â”œâ”€â”€ ğŸ“‚ core/                 # MÃ³dulos de processamento principal
    â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
    â”‚   â”œâ”€â”€ ğŸ“„ video_processor.py    # Classe VideoLoader
    â”‚   â””â”€â”€ ğŸ“„ face_extractor.py     # Classe FaceExtractor
    â”‚
    â”œâ”€â”€ ğŸ“‚ detectors/            # Algoritmos de detecÃ§Ã£o
    â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
    â”‚   â”œâ”€â”€ ğŸ“„ deterministic.py      # Detector baseado em regras
    â”‚   â””â”€â”€ ğŸ“„ ai_model.py           # Classificador IA
    â”‚
    â””â”€â”€ ğŸ“‚ utils/                # FunÃ§Ãµes utilitÃ¡rias
        â”œâ”€â”€ ğŸ“„ __init__.py
        â””â”€â”€ ğŸ“„ metrics.py            # MÃ©tricas de performance
```

</details>

---

## ğŸ”¬ **Aprofundamento TÃ©cnico**

### **ğŸ¯ VideoLoader** (`src/core/video_processor.py`)

<details>
<summary><b>Detalhes de ImplementaÃ§Ã£o</b></summary>

**PadrÃ£o de Design:** PadrÃ£o Generator para eficiÃªncia de memÃ³ria

```python
class VideoLoader:
    @staticmethod
    def load_video(video_path: str, frame_skip: int = 1):
        """
        Generator que produz frames de forma eficiente.
        
        Args:
            video_path: Caminho para arquivo de vÃ­deo
            frame_skip: Processar a cada N frames (otimizaÃ§Ã£o)
            
        Yields:
            Tuple[np.ndarray, int]: (frame, numero_frame)
        """
```

**CaracterÃ­sticas Principais:**
- ğŸ”„ Processamento em streaming com eficiÃªncia de memÃ³ria
- âš¡ Pulo de frames configurÃ¡vel para performance
- ğŸ“Š ExtraÃ§Ã£o de metadados (FPS, resoluÃ§Ã£o, duraÃ§Ã£o)
- ğŸ›¡ï¸ Tratamento de erros e validaÃ§Ã£o

</details>

### **ğŸ‘¤ FaceExtractor** (`src/core/face_extractor.py`)

<details>
<summary><b>DetecÃ§Ã£o Facial AvanÃ§ada</b></summary>

**Algoritmo:** Classificador Haar Cascade (Framework Viola-Jones)

```python
# ParÃ¢metros de detecÃ§Ã£o otimizados
face_cascade.detectMultiScale(
    image=gray_equalized,           # Escala de cinza prÃ©-processada
    scaleFactor=1.15,               # ReduÃ§Ã£o de escala de 15% por nÃ­vel
    minNeighbors=4,                 # RetÃ¢ngulos vizinhos mÃ­nimos
    minSize=(50, 50),               # Tamanho mÃ­nimo da face
    flags=cv2.CASCADE_SCALE_IMAGE   # Escalar imagem, nÃ£o detector
)
```

**Pipeline de ValidaÃ§Ã£o de Qualidade:**
1. **Filtragem de tamanho:** MÃ­nimo 50Ã—50 pixels
2. **ProporÃ§Ã£o aspectual:** 0.8 â‰¤ largura/altura â‰¤ 1.2
3. **EqualizaÃ§Ã£o de histograma:** Contraste melhorado
4. **OtimizaÃ§Ã£o de frame:** MÃ¡x 1280px para performance

</details>

### **ğŸ” DeterministicDetector** (`src/detectors/deterministic.py`)

<details>
<summary><b>MÃ©todos de AnÃ¡lise MatemÃ¡tica</b></summary>

#### **AnÃ¡lise de VariÃ¢ncia de Bordas**

```python
# Operador Laplaciano para detecÃ§Ã£o de bordas
âˆ‡Â²f = âˆ‚Â²f/âˆ‚xÂ² + âˆ‚Â²f/âˆ‚yÂ²

# ImplementaÃ§Ã£o
laplacian = cv2.Laplacian(grayscale_image, cv2.CV_64F)
variance = np.var(laplacian)

# InterpretaÃ§Ã£o
if variance < 100:    # Blur excessivo (artefatos de compressÃ£o)
    return "SUSPEITO: RegiÃµes borradas detectadas"
elif variance > threshold_high:  # Aumento excessivo de nitidez
    return "SUSPEITO: Melhoria artificial de bordas"
```

#### **AnÃ¡lise de DomÃ­nio Espectral**

```python
# Transformada de Fourier 2D
F(u,v) = âˆ‘âˆ‘ f(x,y) Ã— e^(-j2Ï€(ux/M + vy/N))

# ImplementaÃ§Ã£o
f_transform = np.fft.fft2(grayscale_image)
f_shifted = np.fft.fftshift(f_transform)
magnitude = np.abs(f_shifted)

# DetecÃ§Ã£o de anomalias no domÃ­nio da frequÃªncia
mean_magnitude = np.mean(magnitude)
if mean_magnitude < 10.0 or mean_magnitude > 50.0:
    return "SUSPEITO: Anomalias espectrais detectadas"
```

**Limiares EmpÃ­ricos:**
- VariÃ¢ncia de borda: `100.0` (baseado em anÃ¡lise estatÃ­stica)
- Faixa de magnitude FFT: `10.0 - 50.0` (caracterÃ­sticas de imagens naturais)

</details>

### **ğŸ§  DeepFakeClassifier** (`src/detectors/ai_model.py`)

<details>
<summary><b>Arquitetura da Rede Neural</b></summary>

#### **Transfer Learning com MobileNetV2**

**Por que MobileNetV2?**
- âš¡ **EficiÃªncia:** ConvoluÃ§Ãµes separÃ¡veis em profundidade
- ğŸ¯ **PrecisÃ£o:** PrÃ©-treinado na ImageNet (1000 classes)
- ğŸ“± **Portabilidade:** Projetado para implantaÃ§Ã£o mÃ³vel/edge
- ğŸ”„ **Transfer Learning:** RepresentaÃ§Ãµes de caracterÃ­sticas ricas

#### **CabeÃ§a de ClassificaÃ§Ã£o Personalizada**

```python
# Detalhamento camada por camada
base_model = MobileNetV2(
    weights='imagenet',      # Pesos prÃ©-treinados
    include_top=False,       # Remover cabeÃ§a de classificaÃ§Ã£o
    input_shape=(224,224,3)  # Tamanho de entrada padrÃ£o
)
base_model.trainable = False # Congelar extrator de caracterÃ­sticas

# Classificador personalizado
model = tf.keras.Sequential([
    base_model,
    GlobalAveragePooling2D(),    # 7Ã—7Ã—1280 â†’ 1280
    Dense(128, activation='relu'), # CompressÃ£o de caracterÃ­sticas
    Dropout(0.5),                # RegularizaÃ§Ã£o
    Dense(1, activation='sigmoid') # SaÃ­da binÃ¡ria [0,1]
])
```

#### **EstratÃ©gia de Treinamento**

```python
# ConfiguraÃ§Ã£o de otimizador e perda
model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='binary_crossentropy',
    metrics=['accuracy', 'precision', 'recall']
)

# Treinamento com aumento de dados
train_generator = ImageDataGenerator(
    rescale=1./255,
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True
)
```

</details>

---

## ğŸ“Š **MÃ©tricas de Performance e AvaliaÃ§Ã£o**

### **ğŸ“ˆ Indicadores Chave de Performance**

| MÃ©trica | FÃ³rmula | InterpretaÃ§Ã£o |
|---------|---------|---------------|
| **Probabilidade de Autenticidade** | `(1 - probabilidade_fake) Ã— 100` | Maior = mais provÃ¡vel autÃªntico |
| **ConfianÃ§a da IA** | `desvio_padrao(previsoes)^(-1)` | Menor variÃ¢ncia = maior confianÃ§a |
| **Taxa de Frames Suspeitos** | `frames_suspeitos / frames_totais Ã— 100` | Porcentagem de frames suspeitos |
| **Velocidade de Processamento** | `frames_processados / tempo_decorrido` | Taxa de FPS |

### **ğŸ¯ Guia de InterpretaÃ§Ã£o de Resultados**

<table>
<tr>
<td width="50%">

**ğŸŸ¢ Provavelmente AutÃªntico**
- Autenticidade > 70%
- Baixo desvio padrÃ£o (< 0.1)
- Poucos alertas determinÃ­sticos
- PrevisÃµes de IA consistentes

</td>
<td width="50%">

**ğŸ”´ Provavelmente Deepfake**
- Autenticidade < 30%
- MÃºltiplos artefatos visuais
- Altas anomalias espectrais
- ConfianÃ§a da IA > 0.8

</td>
</tr>
<tr>
<td colspan="2">

**ğŸŸ¡ Incerto/Requer RevisÃ£o Humana**
- Autenticidade 30-70%
- Alta variÃ¢ncia nas previsÃµes
- Resultados conflitantes entre detectores
- DetecÃ§Ã£o facial limitada

</td>
</tr>
</table>

### **ğŸ”¬ AnÃ¡lise AvanÃ§ada**

<details>
<summary><b>CaracterÃ­sticas de AnÃ¡lise EstatÃ­stica</b></summary>

```python
# AnÃ¡lise de consistÃªncia temporal
prediction_smoothing = np.convolve(predictions, np.ones(5)/5, mode='valid')

# Intervalos de confianÃ§a
confidence_interval = np.percentile(predictions, [25, 75])

# DetecÃ§Ã£o de anomalias
z_scores = (predictions - np.mean(predictions)) / np.std(predictions)
outliers = predictions[np.abs(z_scores) > 2]
```

</details>

---

## ğŸ› ï¸ **SoluÃ§Ã£o de Problemas e FAQ**

<details>
<summary><b>âŒ Erros Comuns de InstalaÃ§Ã£o</b></summary>

| Erro | Causa | SoluÃ§Ã£o |
|------|-------|---------|
| `ImportError: cv2` | OpenCV nÃ£o instalado | `pip install opencv-python` |
| `ModuleNotFoundError: tensorflow` | TF nÃ£o compatÃ­vel com versÃ£o do Python | Use Python 3.8-3.11 |
| `PermissÃ£o negada` | PrivilÃ©gios insuficientes | Use ambiente virtual ou flag `--user` |
| `CUDA nÃ£o encontrado` | Drivers GPU nÃ£o instalados | Instale toolkit CUDA ou use versÃ£o CPU |

</details>

<details>
<summary><b>âš ï¸ Problemas de Runtime</b></summary>

| Problema | DiagnÃ³stico | SoluÃ§Ã£o |
|----------|-------------|---------|
| Nenhuma face detectada | Qualidade de vÃ­deo ruim / iluminaÃ§Ã£o | Reduza parÃ¢metro `min_face_size` |
| Processamento lento | Arquivos de vÃ­deo grandes | Aumente valor `frame_skip` |
| Falta de memÃ³ria | RAM insuficiente | Processe batches menores |
| Modelo nÃ£o encontrado | Treinamento nÃ£o concluÃ­do | Execute `train_model.py` primeiro |

</details>

<details>
<summary><b>ğŸ”§ OtimizaÃ§Ã£o de Performance</b></summary>

**Para Processamento Mais RÃ¡pido:**
```python
# Reduzir resoluÃ§Ã£o do vÃ­deo
max_dimension = 640  # PadrÃ£o: 1280

# Pular mais frames
frame_skip = 5       # PadrÃ£o: 1

# Usar aceleraÃ§Ã£o GPU (se disponÃ­vel)
tf.config.experimental.set_gpu_growth_enabled(True)
```

**Para Maior PrecisÃ£o:**
```python
# Processar mais frames
frame_skip = 1

# Diminuir limiares de detecÃ§Ã£o
min_face_size = (30, 30)  # PadrÃ£o: (50, 50)

# Usar mÃ©todos de ensemble
combine_multiple_models = True
```

</details>

---

## ğŸš¨ **ConsideraÃ§Ãµes Ã‰ticas e LimitaÃ§Ãµes**

### **âš–ï¸ Uso ResponsÃ¡vel**

<div align="center">

**ğŸ“ Este sistema Ã© projetado apenas para fins educacionais e de pesquisa**

</div>

| âœ… **Uso Apropriado** | âŒ **Uso Inapropriado** |
|----------------------|-------------------------|
| Pesquisa acadÃªmica | AssÃ©dio ou difamaÃ§Ã£o |
| EducaÃ§Ã£o em alfabetizaÃ§Ã£o midiÃ¡tica | Falsas acusaÃ§Ãµes |
| InvestigaÃ§Ã£o forense (com validaÃ§Ã£o de especialista) | ModeraÃ§Ã£o automÃ¡tica de conteÃºdo sem supervisÃ£o humana |
| DemonstraÃ§Ã£o de tecnologia | EvidÃªncia legal sem verificaÃ§Ã£o |

### **ğŸš§ LimitaÃ§Ãµes do Sistema**

<details>
<summary><b>LimitaÃ§Ãµes TÃ©cnicas</b></summary>

- **DependÃªncia de Dados de Treinamento:** Requer dataset diversificado e rotulado
- **RestriÃ§Ãµes de DetecÃ§Ã£o Facial:** Funciona melhor com faces frontais
- **Desafio de Deepfakes Modernos:** Deepfakes de alta qualidade podem escapar da detecÃ§Ã£o
- **Falsos Positivos:** VÃ­deos comprimidos podem acionar alarmes falsos
- **Requisitos Computacionais:** Processamento em tempo real precisa de hardware poderoso

</details>

<details>
<summary><b>ConsideraÃ§Ãµes de PrecisÃ£o</b></summary>

```
âš ï¸  AVISOS IMPORTANTES
â”œâ”€â”€ Resultados sÃ£o probabilÃ­sticos, nÃ£o definitivos
â”œâ”€â”€ Sempre busque verificaÃ§Ã£o humana especializada
â”œâ”€â”€ Considere qualidade e origem do vÃ­deo
â”œâ”€â”€ Entenda os nÃ­veis de confianÃ§a da detecÃ§Ã£o
â””â”€â”€ Use como evidÃªncia de apoio, nÃ£o prova primÃ¡ria
```

</details>

---

## ğŸ”® **Melhorias Futuras**

### **ğŸ›£ï¸ Roadmap**

<table>
<tr>
<td>

**ğŸ”œ Curto Prazo**
- [ ] DetecÃ§Ã£o de mÃºltiplas faces por frame
- [ ] AceleraÃ§Ã£o GPU para treinamento
- [ ] AnÃ¡lise webcam em tempo real
- [ ] ExportaÃ§Ã£o de relatÃ³rios PDF detalhados

</td>
<td>

**ğŸš€ MÃ©dio Prazo**
- [ ] Suporte para mÃºltiplos Ã¢ngulos faciais
- [ ] AnÃ¡lise temporal avanÃ§ada
- [ ] DetecÃ§Ã£o de deepfakes de Ã¡udio
- [ ] OpÃ§Ãµes de implantaÃ§Ã£o em nuvem

</td>
</tr>
<tr>
<td colspan="2">

**ğŸŒŸ VisÃ£o de Longo Prazo**
- [ ] DetecÃ§Ã£o multimodal (vÃ­deo + Ã¡udio + metadados)
- [ ] Aprendizado federado para atualizaÃ§Ãµes de modelo preservando privacidade
- [ ] IntegraÃ§Ã£o com blockchain para verificaÃ§Ã£o de proveniÃªncia
- [ ] Capacidades de monitoramento de redes sociais em tempo real

</td>
</tr>
</table>

---

## ğŸ“š **ReferÃªncias AcadÃªmicas**

<details>
<summary><b>ğŸ“ Fundamentos CientÃ­ficos</b></summary>

### **VisÃ£o Computacional**
- **Viola, P. & Jones, M. (2001).** "DetecÃ§Ã£o RÃ¡pida de Objetos usando uma Cascata Impulsionada de CaracterÃ­sticas Simples." CVPR 2001.
- **Lowe, D. G. (2004).** "CaracterÃ­sticas Distintivas de Imagem a partir de Pontos-chave Invariantes Ã  Escala." IJCV.

### **Deep Learning**
- **Howard, A. G. et al. (2017).** "MobileNets: Redes Neurais Convolucionais Eficientes para AplicaÃ§Ãµes de VisÃ£o MÃ³vel." arXiv:1704.04861.
- **Sandler, M. et al. (2018).** "MobileNetV2: Residuais Invertidos e Gargalos Lineares." CVPR 2018.

### **DetecÃ§Ã£o de Deepfakes**
- **Li, Y. et al. (2019).** "In Ictu Oculi: Expondo VÃ­deos de Rostos Falsos Gerados por IA atravÃ©s da DetecÃ§Ã£o de Piscadas." WIFS 2018.
- **Rossler, A. et al. (2019).** "FaceForensics++: Aprendendo a Detectar Imagens Faciais Manipuladas." ICCV 2019.

</details>

---

## ğŸ¤ **ContribuiÃ§Ã£o e Suporte**

### **ğŸ’¬ Obter Ajuda**

<table>
<tr>
<td>

**ğŸ” Passos para SoluÃ§Ã£o de Problemas:**
1. Verifique a seÃ§Ã£o [SoluÃ§Ã£o de Problemas](#-soluÃ§Ã£o-de-problemas-e-faq)
2. Revise `GUIA_INSTALACAO.md`
3. Verifique compatibilidade da versÃ£o do Python
4. Teste com vÃ­deos de amostra

</td>
<td>

**ğŸ“ Canais de Suporte:**
- ğŸ“§ Instrutor do curso
- ğŸ‘¥ ColaboraÃ§Ã£o em grupo de estudos
- ğŸ“– RevisÃ£o de documentaÃ§Ã£o
- ğŸ”¬ Comunidade de pesquisa

</td>
</tr>
</table>

### **ğŸ¯ Status do Projeto**

<div align="center">

**ğŸ“… Cronograma do Projeto: Curso de VisÃ£o Computacional UNDB 4.0**

**PerÃ­odo de Desenvolvimento:** Novembro - Dezembro 2024  
**Status:** âœ… Desenvolvimento Ativo  
**VersÃ£o:** 1.0.0 (LanÃ§amento Educacional)

---

**ğŸ‘¨â€ğŸ’» PrincÃ­pios de Desenvolvimento Aplicados:**
`Clean Code` â€¢ `PrincÃ­pios SOLID` â€¢ `Type Hinting` â€¢ `DocumentaÃ§Ã£o Abrangente` â€¢ `Arquitetura Modular`

</div>

---

<div align="center">

### **ğŸ“ Projeto Educacional - UNDB 4.0**

*Desenvolvido como parte do curso de VisÃ£o Computacional*

**ğŸ‘¥ Equipe de Desenvolvimento:**

- **Ryan Lucas Rocha Nunes** - 002-024244
- **JoÃ£o Victor da Silva Mesquita** - 002-023096  
- **Rafael Yori Silva Elias** - 002-022028
- **Mackley Rodrigues Freire** - 002-025036
- **Pedro Henrique Carvalho de Oliveira** - 002-023263
- **Paulo SÃ©rgio Costa de Figueiredo Filho** - 002-024167

**ğŸ« InstituiÃ§Ã£o:** Universidade Undb  
**ğŸ“š Disciplina:** VisÃ£o Computacional 4.0  
**ğŸ“… PerÃ­odo:** 2024/2025

---

</div>
